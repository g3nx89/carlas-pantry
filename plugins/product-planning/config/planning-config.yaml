# Planning Configuration
# Configuration for /product-planning:plan command with ST/CLI integration

# =============================================================================
# FEATURE FLAGS
# =============================================================================
# Toggle improvements on/off for gradual rollout and rollback capability
# See PROPOSAL-planning-enhancements.md for detailed documentation

feature_flags:
  # Universal Improvements (all modes)
  s1_self_critique:
    enabled: true
    description: "Agent self-verification before submission"
    rollback: "Set false to remove self-critique from agents"
    mode_thresholds:
      rapid: { min_questions: 3, pass_threshold: 2 }
      standard: { min_questions: 5, pass_threshold: 4 }
      advanced: { min_questions: 5, pass_threshold: 4 }
      complete: { min_questions: 5, pass_threshold: 5 }

  s2_cot_prefix:
    enabled: true
    description: "Zero-Shot Chain-of-Thought reasoning prefix"
    rollback: "Set false to remove CoT sections from agents"

  a3_adaptive_depth:
    enabled: true
    description: "Risk-based research depth adjustment"
    rollback: "Set false for mode-based depth only"

  a5_post_planning_menu:
    enabled: true
    description: "Interactive menu after planning completion"
    rollback: "Set false to skip menu"

  # Advanced/Complete Mode Improvements
  s3_judge_gates:
    enabled: true
    description: "Quality gates between phases"
    rollback: "Set false to skip gates"
    modes: [advanced, complete]
    gates:
      - after_phase: 2
        name: "Research Completeness"
      - after_phase: 4
        name: "Architecture Quality"
      - after_phase: 7
        name: "Test Coverage"

  s4_adaptive_strategy:
    enabled: true
    description: "Adaptive synthesis strategy based on evaluation"
    rollback: "Set false to always synthesize"
    modes: [advanced, complete]

  a4_expert_review:
    enabled: true
    description: "Security and simplicity expert review"
    rollback: "Set false to skip Phase 6b"
    modes: [advanced, complete]

  # Complete Mode Only Improvements
  s5_tot_architecture:
    enabled: true
    description: "Hybrid Tree-of-Thoughts architecture exploration"
    rollback: "Set false to use standard MPA"
    modes: [complete]
    requires_mcp: false  # Uses internal agents
    requires: [s4_adaptive_strategy]  # ToT needs adaptive strategy for branch selection

  s6_multi_judge_debate:
    enabled: true
    description: "Multi-round debate for validation"
    rollback: "Set false to use single-round"
    modes: [complete]
    requires_mcp: false  # PAL removed — S6 debate uses CLI dispatch or internal judges
    requires: [s3_judge_gates]  # Debates need judge infrastructure for scoring

  # Sequential Thinking Enhancements
  st_fork_join_architecture:
    enabled: true
    description: "Fork-Join branching for Phase 4 architecture exploration"
    rollback: "Set false to use linear T7-T10"
    modes: [complete]
    requires_mcp: true  # Requires mcp__sequential-thinking__sequentialthinking
    cost_impact: "+3 ST calls per Phase 4 (~40% increase)"

  st_revision_reconciliation:
    enabled: true
    description: "Revision-based reconciliation when ThinkDeep contradicts risk analysis"
    rollback: "Set false to skip ST revision (manual reconciliation)"
    modes: [complete, advanced]
    requires_mcp: true
    cost_impact: "+1 ST call per Phase 7 (~10% increase)"

  st_redteam_analysis:
    enabled: true
    description: "Red team adversarial branch in Phase 7 risk analysis"
    rollback: "Set false to skip adversarial perspective"
    modes: [complete, advanced]
    requires_mcp: true
    cost_impact: "+2 ST calls per Phase 7 (~20% increase)"

  st_tao_loops:
    enabled: true
    description: "TAO (Think-Analyze-Output) structured pause after MPA agent outputs"
    rollback: "Set false to skip structured synthesis pause"
    modes: [complete, advanced, standard]
    requires_mcp: true
    cost_impact: "+3 ST calls per MPA phase (~30% per phase)"

  st_dynamic_extension:
    enabled: true
    description: "Allow ST chains to extend when complexity exceeds initial estimates"
    rollback: "Set false for fixed thought counts"
    modes: [complete]
    requires_mcp: true
    triggers:
      - "Component count > 10"
      - "Unexpected integration points discovered"
      - "Security/compliance requirements more extensive than expected"
    cost_impact: "0-2 additional ST calls situational"

  st_agent_invocation:
    enabled: true
    description: "Agents invoke ST MCP tool instead of inline reasoning"
    rollback: "Set false for inline reasoning only (no ST in agents)"
    modes: [complete, advanced]
    requires_mcp: true
    cost_impact: "Replaces inline reasoning (~5% total increase)"

  st_checkpoint:
    enabled: true
    description: "Checkpoint mechanism (Rule of 5) for long ST chains"
    rollback: "Set false to skip checkpoints (chains may become unfocused)"
    modes: [complete, advanced, standard]
    requires_mcp: true
    cost_impact: "+1 ST call per 5 thoughts (~20% for long chains)"
    triggers:
      - "ST chain exceeds 5 thoughts"
      - "Phase involves complex multi-step analysis"
      - "Exploration requires consolidation"

  st_task_decomposition:
    enabled: true
    description: "Structured task decomposition for tech-lead agent"
    rollback: "Set false for unstructured task breakdown"
    modes: [complete, advanced, standard]
    requires_mcp: true
    cost_impact: "+4 ST calls per task breakdown (~15% Phase 9 increase)"

  # CLI Dispatch Integration
  cli_context_isolation:
    enabled: true
    description: "Use CLI dispatch for context-isolated CLI agent analysis"
    rollback: "Set false to use inline agents only"
    modes: [complete, advanced]
    cost_impact: "Marginal increase; ~30KB coordinator context savings"

  cli_custom_roles:
    enabled: true
    description: "Use specialized CLI roles with filesystem exploration directives"
    rollback: "Set false to skip CLI roles"
    modes: [complete, advanced]
    requires: [cli_context_isolation]
    cost_impact: "~$0.15-0.30 additional; ~5-10 min latency for all roles"

  # Context Improvements
  a1_flow_analysis:
    enabled: true
    description: "User flow analysis in Phase 2b"
    rollback: "Set false to skip flow analysis"
    modes: [complete]

  a2_learnings_researcher:
    enabled: true
    description: "Institutional knowledge integration"
    rollback: "Set false to skip learnings search"
    modes: [complete, advanced, standard]

  # Multi-Agent Collaboration Improvements (Phases A + B)
  s7_mpa_deliberation:
    enabled: false
    description: "Structured MPA synthesis with Round 2 cross-review and contradiction logging"
    rollback: "Set false to use standard one-shot MPA synthesis"
    modes: [complete, advanced]
    cost_impact: "Complete: +3 agent re-dispatches; Advanced: inline synthesis only"

  s8_convergence_detection:
    enabled: false
    description: "Jaccard similarity-based convergence measurement for MPA agent outputs"
    rollback: "Set false to use default merge strategy regardless of agreement level"
    modes: [complete, advanced]
    cost_impact: "Negligible — keyword extraction + set comparison"

  s10_team_presets:
    enabled: false
    description: "User-selectable agent team configurations (balanced, rapid_prototype)"
    rollback: "Set false to always use default agent configuration per mode"
    modes: [complete, advanced, standard]
    cost_impact: "rapid_prototype reduces agent count; balanced is default behavior"

  s12_specify_gate:
    enabled: false
    description: "5-dimension specification quality scoring gate in Phase 3"
    rollback: "Set false to use standard question generation without scoring"
    modes: [complete, advanced, standard, rapid]
    cost_impact: "0-3 additional user interaction rounds"

  s13_confidence_gated_review:
    enabled: false
    description: "Confidence-scored expert review with tri-state outcome and iteration"
    rollback: "Set false to use binary blocking/advisory expert review"
    modes: [complete, advanced]
    cost_impact: "0-2 additional user interaction rounds"

  a6_context_protocol:
    enabled: false
    description: "Accumulated decision/question/risk context propagation across phases"
    rollback: "Set false to use summary-only context between phases"
    modes: [complete, advanced, standard]
    cost_impact: "~100-500 tokens additional context per coordinator dispatch"

# =============================================================================
# ADAPTIVE RESEARCH DEPTH (A3)
# =============================================================================
# Adjusts research intensity based on risk indicators in the feature spec

research_depth:
  # Keywords that indicate higher risk (case-insensitive)
  risk_keywords:
    high:
      - payment
      - payments
      - billing
      - credit card
      - authentication
      - auth
      - authorization
      - security
      - encryption
      - password
      - credentials
      - PII
      - GDPR
      - HIPAA
      - SOC2
      - compliance
      - financial
      - transaction
      # Production-mature (v1.3.0 alignment with specify)
      - CCPA
      - data retention
      - audit log
      - circuit breaker
      - deployment rollback
      - blast radius
    medium:
      - API
      - integration
      - migration
      - database
      - schema
      - performance
      - scaling
      - concurrent
      - async
      - cache
      - session
      - state
      # Production-mature (v1.3.0 alignment with specify)
      - rate limit
      - backpressure
      - failover
      - health check
      - feature flag
      - degraded mode
      - p95
      - p99
      - external dependency
      - third-party
      - deployment pipeline

  # Depth levels and what they mean
  levels:
    minimal:
      agents: 1
      search_scope: "direct matches only"
      analysis_depth: "surface level"
      st_templates: []
    standard:
      agents: 2
      search_scope: "related patterns"
      analysis_depth: "moderate"
      st_templates: [T4, T5]
    deep:
      agents: 3
      search_scope: "comprehensive exploration"
      analysis_depth: "thorough"
      st_templates: [T4, T5, T6]

  # Mode × Risk interaction matrix
  # Rows: analysis mode, Columns: risk level
  depth_matrix:
    rapid:
      low: minimal
      medium: minimal
      high: standard
    standard:
      low: minimal
      medium: standard
      high: standard
    advanced:
      low: standard
      medium: standard
      high: deep
    complete:
      low: standard
      medium: deep
      high: deep

# =============================================================================
# INSTITUTIONAL KNOWLEDGE (A2)
# =============================================================================
# Configuration for learnings-researcher agent and knowledge base integration

institutional_knowledge:
  # Expected locations for knowledge base
  paths:
    solutions: "docs/solutions/"
    critical_patterns: "docs/critical-patterns.md"
    anti_patterns: "docs/anti-patterns.md"  # Optional

  # Schema for solution records
  schema_template: "$CLAUDE_PLUGIN_ROOT/templates/learnings-schema.yaml"

  # Relevance scoring criteria
  relevance:
    high:
      criteria: "Same domain + same technology + similar constraints"
      action: "Apply directly to current feature"
    medium:
      criteria: "Same domain OR same technology"
      action: "Consider for adaptation"
    low:
      criteria: "Related but different context"
      action: "Reference only"

  # Behavior when knowledge base doesn't exist
  graceful_degradation:
    log_message: "No institutional knowledge base found"
    suggest_creation: true
    continue_without: true

# =============================================================================
# REQUIREMENTS CONTEXT PROPAGATION
# =============================================================================
# Controls how original requirements (spec.md) are propagated across phases
# to prevent context dilution in multi-phase workflows.
#
# Three mechanisms work together (defence in depth):
# 1. Requirements Digest: compact summary injected into every coordinator dispatch (~300 tokens)
# 2. Requirements Anchor: consolidated spec + user clarifications written by Phase 3 (~800 tokens)
# 3. Direct spec.md read: phases that need deep requirement context list spec.md in artifacts_read

requirements_context:
  # Requirements digest: extracted in Phase 1, injected in every coordinator dispatch prompt
  digest_max_tokens: 300
  inject_in_dispatch: true    # Set false to disable digest injection in coordinator prompts

  # Requirements anchor: consolidated document written by Phase 3
  anchor_max_tokens: 800
  anchor_file: "requirements-anchor.md"

  # Priority order when anchor content exceeds budget (most important first)
  anchor_priority:
    - "acceptance_criteria"
    - "key_constraints"
    - "user_stories"
    - "scope_boundaries"
    - "user_decisions"

# =============================================================================
# ANALYSIS MODES
# =============================================================================
# Hierarchical modes with graceful degradation when MCP tools unavailable

analysis_modes:
  complete:
    description: "Full analysis with CLI Deep Analysis + Sequential Thinking + Consensus + Full Test Plan"
    mpa_agents: 6  # code-explorer, software-architect, tech-lead + 3 QA agents (MPA)
    cli_deep_analysis_dispatches: 9  # 3 perspectives × 3 CLIs
    sequential_thinking_enabled: true
    cli_consensus_enabled: true  # Both plan validation AND test coverage validation
    requires_mcp: true
    estimated_cost: "$1.00-1.80"  # Includes 9-phase workflow with test planning

  advanced:
    description: "MPA + CLI Deep Analysis (reduced perspectives) + Test Plan"
    mpa_agents: 5  # code-explorer, software-architect, tech-lead + 2 QA agents
    cli_deep_analysis_dispatches: 6  # 2 perspectives × 3 CLIs
    sequential_thinking_enabled: true  # Enabled for ST features: risk, revision, redteam, TAO, checkpoint, task decomposition
    cli_consensus_enabled: true  # Test coverage validation only
    requires_mcp: true
    estimated_cost: "$0.55-0.95"

  standard:
    description: "MPA only (no CLI deep analysis/ST) + Basic Test Plan"
    mpa_agents: 4  # code-explorer, software-architect, tech-lead + qa-strategist
    cli_deep_analysis_dispatches: 0
    sequential_thinking_enabled: false
    cli_consensus_enabled: false
    requires_mcp: false
    estimated_cost: "$0.15-0.30"

  rapid:
    description: "Single agent fast path + Minimal Test Plan"
    mpa_agents: 2  # software-architect + qa-strategist
    cli_deep_analysis_dispatches: 0
    sequential_thinking_enabled: false
    cli_consensus_enabled: false
    requires_mcp: false
    estimated_cost: "$0.05-0.12"

# Note on CLI names: The CLI identifiers (gemini, codex) are configurable.
# Update these to match your available CLI installations.

# =============================================================================
# MODE AUTO-SUGGESTION
# =============================================================================
# Heuristics for suggesting analysis mode based on feature characteristics

mode_suggestion:
  enabled: true
  description: "Automatic mode suggestion based on feature characteristics"

  # Evaluation order: first matching rule wins
  rules:
    - name: "complex_feature"
      conditions:
        spec_word_count: ">= 2000"
        OR:
          high_risk_keywords: ">= 3"
      suggest: complete
      rationale: "Large spec or multiple high-risk areas require full analysis"

    - name: "risky_feature"
      conditions:
        high_risk_keywords: ">= 2"
        OR:
          estimated_files: ">= 15"
      suggest: advanced
      rationale: "Significant risk or large scope benefits from CLI deep analysis"

    - name: "moderate_feature"
      conditions:
        spec_word_count: ">= 500"
        OR:
          estimated_files: ">= 5"
      suggest: standard
      rationale: "Moderate complexity benefits from MPA without external models"

    - name: "simple_feature"
      conditions:
        default: true
      suggest: rapid
      rationale: "Small features can use fast path"

  # Keyword patterns for risk detection (reuses research_depth.risk_keywords)
  risk_detection:
    use_config: "research_depth.risk_keywords"

  # Output format for suggestion
  output_template: |
    Detected: {high_risk_count} high-risk keywords ({keywords_sample})
    Estimated: {file_count} files affected
    Recommended: {mode} mode (~{cost_estimate})

# Graceful degradation rules
degradation:
  if_cli_unavailable:
    complete: standard  # Without CLI dispatch, falls back to standard (internal agents only)
    advanced: standard
  if_st_unavailable:
    complete: advanced  # Keeps CLI analysis but loses ST structured reasoning
    use_internal_reasoning: true
    mark_degraded: true

# =============================================================================
# SEQUENTIAL THINKING
# =============================================================================

sequential_thinking:
  # Template groups loaded from templates/sequential-thinking-templates.md
  template_groups:
    # Standard groups (existing)
    problem_decomposition: [T1, T2, T3]
    codebase_analysis: [T4, T5, T6]
    architecture_design: [T7, T8, T9, T10]
    risk_assessment: [T11, T12, T13]
    plan_validation: [T14, T15, T16]
    test_risk_analysis: [T-RISK-1, T-RISK-2, T-RISK-3]

    # NEW: Fork-Join architecture exploration (st_fork_join_architecture)
    architecture_fork_join: [T7a, T7b, T7c, T7d, T8a, T8b]

    # NEW: Revision for reconciliation (st_revision_reconciliation)
    test_risk_revision: [T-RISK-REVISION]

    # NEW: Red team adversarial analysis (st_redteam_analysis)
    test_risk_redteam: [T-RISK-REDTEAM, T-RISK-REDTEAM-SYNTHESIS, T-RISK-REDTEAM-FINALIZE]

    # NEW: TAO loop agent synthesis (st_tao_loops)
    agent_analysis: [T-AGENT-ANALYSIS, T-AGENT-SYNTHESIS, T-AGENT-VALIDATION]

    # NEW: Dynamic extension (st_dynamic_extension)
    extension: [T-EXTENSION]

    # NEW: Checkpoint management (Rule of 5)
    checkpoint: [T-CHECKPOINT]

    # NEW: Task decomposition (tech-lead)
    task_decomposition: [T-TASK-DECOMPOSE, T-TASK-SEQUENCE, T-TASK-VALIDATE, T-TASK-FINALIZE]

  # When to use each group
  phase_mapping:
    setup: null  # No ST needed
    research: [codebase_analysis, agent_analysis, checkpoint]  # TAO + checkpoint for long explorations
    clarification: [problem_decomposition]
    architecture: [architecture_design, architecture_fork_join, risk_assessment, agent_analysis, checkpoint]  # Fork-Join, TAO, checkpoint
    thinkdeep: null  # CLI deep analysis handles this
    validation: [plan_validation]
    test_strategy: [test_risk_analysis, test_risk_revision, test_risk_redteam, agent_analysis, checkpoint]  # Revision, Red Team, TAO, checkpoint
    test_coverage_validation: null  # CLI consensus scoring handles this
    completion: [task_decomposition]  # Task breakdown uses structured decomposition

  # Feature flag to template group mapping
  flag_to_templates:
    st_fork_join_architecture: architecture_fork_join
    st_revision_reconciliation: test_risk_revision
    st_redteam_analysis: test_risk_redteam
    st_tao_loops: agent_analysis
    st_dynamic_extension: extension
    st_checkpoint: checkpoint
    st_task_decomposition: task_decomposition

  # Checkpoint after each group
  checkpoint_after_group: true

# =============================================================================
# CLI DEEP ANALYSIS (replaces PAL ThinkDeep)
# =============================================================================

cli_analysis:
  deep_analysis:
    # CLIs to use (maps to dispatch-cli-agent.sh --cli parameter)
    # NOTE: These are the CLI binaries dispatched via Bash process-group dispatch.
    # Add new entries when additional CLIs become available (script supports any CLI).
    clis:
      - gemini    # Broad exploration, large context window
      - codex     # Code-level precision, import chain analysis
      - opencode  # UX/Product lens, accessibility, user flow analysis

    # Architecture-focused perspectives
    perspectives:
      performance:
        focus: scalability, latency, resource_efficiency, bottlenecks
        prompt_template: |
          Analyze this architecture plan from a PERFORMANCE perspective.

          MY CURRENT ANALYSIS:
          {current_analysis}

          EXTEND MY ANALYSIS - Focus on:
          1. Scalability bottlenecks and horizontal/vertical scaling implications
          2. Latency-sensitive paths and potential optimizations
          3. Resource efficiency (memory, CPU, I/O patterns)
          4. Caching strategies and data locality
          5. Async patterns and parallelization opportunities
        dispatch_to_all_clis: true

      maintainability:
        focus: code_quality, extensibility, technical_debt, modularity
        prompt_template: |
          Analyze this architecture plan from a MAINTAINABILITY perspective.

          MY CURRENT ANALYSIS:
          {current_analysis}

          EXTEND MY ANALYSIS - Focus on:
          1. Coupling and cohesion of proposed components
          2. Extensibility for future requirements
          3. Technical debt introduced vs. avoided
          4. Testing strategy and testability
          5. Code patterns that aid or hinder maintainability
        dispatch_to_all_clis: true

      security:
        focus: threat_modeling, compliance, vulnerabilities, data_protection
        prompt_template: |
          Analyze this architecture plan from a SECURITY perspective.

          MY CURRENT ANALYSIS:
          {current_analysis}

          EXTEND MY ANALYSIS - Focus on:
          1. Threat modeling (STRIDE categories)
          2. Authentication and authorization patterns
          3. Data protection (at rest, in transit)
          4. Input validation and injection prevention
          5. Compliance considerations (GDPR, SOC2, etc.)
        dispatch_to_all_clis: true

    # Mode variations
    mode_matrix:
      complete:
        perspectives: [performance, maintainability, security]
        clis_per_perspective: 3
        total_dispatches: 9
      advanced:
        perspectives: [performance, security]  # Skip maintainability
        clis_per_perspective: 3
        total_dispatches: 6

    # Problem context template
    problem_context_template: |
      IMPORTANT: This is ARCHITECTURE PLANNING, not code review.
      We are designing the implementation approach for a feature.
      Please analyze from an architecture perspective.

      FEATURE SUMMARY:
      {feature_summary}

      CODEBASE CONTEXT:
      {codebase_patterns}

    # Output aggregation
    output:
      file: "{FEATURE_DIR}/analysis/thinkdeep-insights.md"
      include_convergent: true  # Where all models agree
      include_divergent: true   # Where models disagree → FLAG for decisions
      priority_from_convergence: true  # Agreement = higher priority

  # =============================================================================
  # CLI CONSENSUS SCORING (replaces PAL Consensus)
  # =============================================================================

  consensus:
    min_clis: 1  # Minimum for valid consensus (1 CLI with self-challenge suffices)

    # CLI stance assignments
    cli_stances:
      gemini:
        stance: advocate
        stance_prompt: "Highlight strengths, give benefit of doubt on ambiguous items"
      codex:
        stance: challenger
        stance_prompt: "Actively find gaps, risks, and overlooked failure modes. Score conservatively."
      opencode:
        stance: product_lens
        stance_prompt: "Evaluate from user experience and product alignment perspective. Score based on user value delivery, accessibility, and product-market fit."

    # Score divergence thresholds
    divergence:
      low: 1.0       # < 1.0: accept averaged scores
      high: 4.0       # > 4.0: re-dispatch with challenge prompt

    # Scoring dimensions (20 points total, 4 per dimension)
    dimensions:
      problem_understanding:
        weight: 0.20
        criteria: "Clear problem statement, root cause identified, scope defined"
      architecture_quality:
        weight: 0.25
        criteria: "Sound design principles, appropriate patterns, good abstractions"
      risk_mitigation:
        weight: 0.20
        criteria: "Risks identified, mitigations planned, fallback strategies"
      implementation_clarity:
        weight: 0.20
        criteria: "Clear steps, dependencies mapped, acceptance criteria defined"
      feasibility:
        weight: 0.15
        criteria: "Realistic scope, resource considerations, timeline alignment"

    # Thresholds with explicit comparison semantics (per CLAUDE.md guidelines)
    # GREEN: score >= 16 → proceed to implementation
    # YELLOW: score >= 12 AND score < 16 → proceed with documented risks
    # RED: score < 12 → requires revision (boundary value: 12)
    thresholds:
      green: 16       # score >= 16: proceed to implementation
      yellow: 12      # score >= 12 AND < 16: proceed with documented risks
      red: 12         # score < 12: requires revision (boundary is 12)

    # Output
    output:
      file: "{FEATURE_DIR}/analysis/consensus-validation.md"
      include_per_model_scores: true
      include_debate_summary: true

# =============================================================================
# MPA (MULTI-PERSPECTIVE ANALYSIS)
# =============================================================================

mpa:
  agents:
    # Phase 2-4 Agents
    code_explorer:
      file: "agents/code-explorer.md"
      focus: "Codebase patterns, similar features, integration points"
      output: "{FEATURE_DIR}/analysis/codebase-analysis.md"

    software_architect:
      file: "agents/software-architect.md"
      focus: "Architecture options, design trade-offs, component design"
      output: "{FEATURE_DIR}/analysis/architecture-options.md"

    tech_lead:
      file: "agents/tech-lead.md"
      focus: "Task breakdown, dependencies, complexity, risks"
      output: "{FEATURE_DIR}/analysis/task-breakdown.md"

    # Phase 7 QA Agents (MPA for test planning)
    qa_strategist:
      file: "agents/qa-strategist.md"
      focus: "V-Model test strategy, UAT scripts, coverage matrix"
      output: "{FEATURE_DIR}/analysis/test-strategy-general.md"
      modes: [complete, advanced, standard, rapid]

    qa_security:
      file: "agents/qa-security.md"
      focus: "Security testing, STRIDE analysis, authentication/authorization"
      output: "{FEATURE_DIR}/analysis/test-strategy-security.md"
      modes: [complete, advanced]  # Only in higher modes

    qa_performance:
      file: "agents/qa-performance.md"
      focus: "Performance testing, load/stress tests, latency requirements"
      output: "{FEATURE_DIR}/analysis/test-strategy-performance.md"
      modes: [complete, advanced]  # Only in higher modes

  synthesis:
    merge_strategy: "convergent_prioritization"
    deduplication_threshold: 0.80
    priority_weights:
      impact: 0.35
      risk: 0.30
      complexity: 0.20
      dependencies: 0.15

  # S1: MPA Deliberation — structured multi-round synthesis
  deliberation:
    enabled_via_flag: "s7_mpa_deliberation"
    round_2_dispatch: true           # Re-dispatch agents with peer outputs (Complete only)
    round_2_inline_synthesis: true   # Inline synthesis without re-dispatch (Advanced)
    contradiction_log: true          # Generate contradiction log during synthesis
    max_round_2_agents: 3            # Max agents to re-dispatch in Round 2

  # S2: Convergence Detection — measure agent agreement
  # NOTE: Jaccard similarity measures vocabulary overlap, not semantic agreement.
  # Agents sharing domain vocabulary may score high even with different conclusions.
  # Use convergence as a heuristic signal for synthesis strategy, not a definitive
  # measure. See references/mpa-synthesis-pattern.md for known limitations.
  convergence_detection:
    enabled_via_flag: "s8_convergence_detection"
    high_threshold: 0.70             # Jaccard similarity >= 0.70 = high convergence
    medium_threshold: 0.40           # Jaccard similarity >= 0.40 = medium convergence
    keyword_count: 20                # Top N keywords to extract per agent
    strategies:
      high: "merge_with_unique_highlights"
      medium: "weighted_merge_flag_divergence"
      low: "present_all_options"

  # S5: Team Presets — user-selectable agent configurations
  team_presets:
    enabled_via_flag: "s10_team_presets"
    presets:
      balanced:
        description: "All MPA agents active. Full convergence + deliberation."
        phase_4_agents: [software-architect, wildcard-architect, architecture-pruning-judge]
        phase_7_agents: [qa-strategist, qa-security, qa-performance]
      rapid_prototype:
        description: "Minimal agents for fast iteration."
        phase_4_agents: [software-architect]
        phase_7_agents: [qa-strategist]

  # Preset auto-suggestion based on mode + spec characteristics
  preset_suggestion:
    enabled: true
    rules:
      - condition: "analysis_mode == rapid"
        suggest: null               # No preset in rapid mode
      - condition: "analysis_mode == standard"
        suggest: "balanced"
      - condition: "high_risk_count >= 2"
        suggest: "balanced"
      - condition: "spec_word_count < 500"
        suggest: "rapid_prototype"

# =============================================================================
# STATE MANAGEMENT
# =============================================================================

state:
  file: "{FEATURE_DIR}/.planning-state.local.md"
  format: yaml_frontmatter

  checkpoints:
    - SETUP
    - RESEARCH
    - CLARIFICATION
    - ARCHITECTURE
    - THINKDEEP
    - VALIDATION
    - EXPERT_REVIEW          # Phase 6b: Security + simplicity review
    - TEST_STRATEGY          # Phase 7: V-Model test planning
    - TEST_COVERAGE_VALIDATION  # Phase 8: Coverage validation
    - ASSET_CONSOLIDATION       # Phase 8b: Asset manifest generation
    - COMPLETION
    - RETROSPECTIVE             # Phase 10: Planning retrospective

  # User decisions are immutable once saved
  immutable_fields:
    - user_decisions
    - approved_architecture
    - approved_test_strategy  # Test strategy locked after Phase 8
    - task_clarifications     # Task clarifications locked after Phase 9
    - assets                  # Asset manifest state locked after Phase 8b

  # Version tracking for drift detection
  version_fields:
    - spec_version
    - plan_version
    - design_version
    - test_plan_version  # Track test plan version for updates

  # Lock to prevent concurrent execution
  lock:
    file: "{FEATURE_DIR}/.planning.lock"
    timeout_minutes: 60

  # S6: Context Protocol — accumulated decision propagation
  context_protocol:
    enabled_via_flag: "a6_context_protocol"
    decision_propagation:
      accumulate_from: "all_prior_summaries"
      respect_high_confidence: true   # HIGH-confidence decisions should not be contradicted
      carry_forward_open_questions: true
      carry_forward_risks: true
    context_pack:
      # Per-category budgets prevent any single category from crowding out others.
      # Total budget ~500 tokens, split by purpose:
      category_budgets:
        decisions: 200                # HIGH-confidence first, then MEDIUM
        questions: 150                # HIGH-priority first, then MEDIUM
        risks: 150                    # HIGH-severity first, then MEDIUM
      truncation_strategies:
        decisions: "keep_high_confidence_first"
        questions: "keep_high_priority_first"
        risks: "keep_high_severity_first"
      include_in_prompt: true         # Inject as "## Accumulated Context" section

# =============================================================================
# LIMITS AND GUARDS
# =============================================================================

limits:
  max_clarifying_questions: 15
  max_architecture_options: 4
  max_tasks_per_story: 8
  max_rounds: 10  # Circuit breaker

guards:
  require_spec_exists: true
  require_constitution_exists: true
  constitution_path: "specs/constitution.md"
  block_on_gate_failure: true
  lock_stale_timeout_minutes: 60

# =============================================================================
# SPECIFY GATE (S8 — Phase 3)
# =============================================================================
# 5-dimension specification quality scoring before question generation

specify_gate:
  enabled_via_flag: "s12_specify_gate"
  pass_threshold: 7                  # Score >= 7/10: skip targeted questions
  min_acceptable: 6                  # Score < 6 after max iterations: set low_specify_score flag
  dimensions:
    value:
      weight: 1
      description: "Value clarity — user/business problem and success metric"
    scope:
      weight: 1
      description: "Scope definition — clear in/out of scope boundaries"
    acceptance:
      weight: 1
      description: "Acceptance criteria quality — measurable, testable ACs"
    constraints:
      weight: 1
      description: "Constraints & dependencies — full list with priorities"
    risk:
      weight: 1
      description: "Risk identification — risks with mitigations"
  scoring:
    min: 0                           # Per dimension
    max: 2                           # Per dimension
    labels:
      0: "Missing"
      1: "Partial"
      2: "Clear"

# =============================================================================
# EXPERT REVIEW (S9 — Phase 6b)
# =============================================================================
# Confidence-gated expert review with tri-state outcome

expert_review:
  enabled_via_flag: "s13_confidence_gated_review"
  confidence_threshold: 80           # Findings below this are demoted to advisory
  outcomes:
    pass: "No high-confidence blocking findings"
    pass_with_risk: "Blocking findings exist but all have mitigations"
    fail: "Unmitigated blocking findings above confidence threshold"
  user_options_on_fail:
    - "Redesign — return to Phase 4 with security constraints"
    - "Override — acknowledge risks and proceed (immutable)"
    - "Provide context — re-evaluate with additional information"

# =============================================================================
# CIRCUIT BREAKER
# =============================================================================
# Generic retry-with-escalation limits for iterative improvement loops

circuit_breaker:
  specify_gate:
    max_iterations: 3                # S8: Max question rounds in Phase 3
    escalation: "set_low_specify_flag"
  expert_review:
    max_iterations: 2                # S9: Max re-evaluation rounds in Phase 6b
    escalation: "force_user_choice"
  convergence:
    max_rounds: 2                    # S2: Max convergence improvement attempts
    escalation: "accept_low_convergence"

# =============================================================================
# TEST PLANNING (V-MODEL)
# =============================================================================

test_planning:
  # Sequential Thinking templates for test planning
  sequential_thinking:
    risk_analysis:
      - T-RISK-1  # Failure mode identification
      - T-RISK-2  # Risk prioritization
      - T-RISK-3  # Risk to test mapping

  # Test level definitions (V-Model alignment)
  test_levels:
    unit:
      loop: inner
      trigger: every_commit
      executor: ci_pipeline
      pattern: tdd
      scope: single_function_or_class
      mocks: all_external_dependencies

    integration:
      loop: inner
      trigger: every_pr
      executor: ci_pipeline
      pattern: post_implementation
      scope: component_interaction
      mocks: external_services_only

    e2e:
      loop: outer
      trigger: pre_merge
      executor: qa_automation
      pattern: scenario_based
      scope: complete_user_flow
      evidence_required: true

    uat:
      loop: outer
      trigger: pre_release
      executor: product_owner
      pattern: given_when_then
      scope: user_story_validation
      sign_off_required: true

    exploratory:
      loop: outer
      trigger: pre_release
      executor: qa_engineer
      pattern: charter_based
      scope: edge_cases_and_chaos
      time_boxed: true

  # Coverage validation settings
  coverage:
    # CLI Consensus for test coverage validation
    consensus:
      dimensions:
        ac_coverage:
          weight: 0.25
          criteria: "All acceptance criteria mapped to tests"
        risk_coverage:
          weight: 0.25
          criteria: "All Critical/High risks have test coverage"
        uat_completeness:
          weight: 0.20
          criteria: "UAT scripts are clear and executable by non-technical users"
        test_independence:
          weight: 0.15
          criteria: "Tests can run in isolation without dependencies"
        maintainability:
          weight: 0.15
          criteria: "Tests are not brittle or over-specified"

      # Thresholds with explicit comparison semantics (per CLAUDE.md guidelines)
      # GREEN: score >= 80% → proceed with TDD
      # YELLOW: score >= 65% AND score < 80% → proceed with documented gaps
      # RED: score < 65% → add more tests (boundary value: 65)
      thresholds:
        green: 80       # score >= 80: proceed with TDD
        yellow: 65      # score >= 65 AND < 80: proceed with documented gaps
        red: 65         # score < 65: add more tests (boundary is 65)

    # Required coverage targets
    targets:
      acceptance_criteria: 100  # Every AC must have a test
      critical_risks: 100       # Every Critical risk must have coverage
      high_risks: 100           # Every High risk must have coverage
      user_stories: 100         # Every story must have UAT

  # UAT configuration
  uat:
    format: given_when_then
    evidence:
      screenshots_required: true
      sign_off_required: true
    templates:
      script: "templates/uat-script-template.md"

  # QA agent: see mpa.agents.qa_strategist for canonical definition

  # Output artifact structure
  output:
    directories:
      - "{FEATURE_DIR}/test-cases/unit/"
      - "{FEATURE_DIR}/test-cases/integration/"
      - "{FEATURE_DIR}/test-cases/e2e/"
      - "{FEATURE_DIR}/test-cases/uat/"

    artifacts:
      test_plan: "{FEATURE_DIR}/test-plan.md"
      coverage_validation: "{FEATURE_DIR}/analysis/test-coverage-validation.md"

# =============================================================================
# TASK GENERATION (Phase 9)
# =============================================================================
# Configuration for integrated task generation in Phase 9

task_generation:
  # Template for task breakdown
  template: "$CLAUDE_PLUGIN_ROOT/templates/tasks-template.md"

  # Output artifact
  output: "{FEATURE_DIR}/tasks.md"

  # Regeneration mode - allows Phase 9 only execution when planning is complete
  regeneration:
    enabled: true
    trigger_phrases:
      - "regenerate tasks"
      - "update tasks"
      - "rerun Phase 9"
      - "refresh tasks.md"
    required_artifacts:
      - "{FEATURE_DIR}/spec.md"
      - "{FEATURE_DIR}/plan.md"
      - "{FEATURE_DIR}/design.md"
      - "{FEATURE_DIR}/test-plan.md"
    min_phase_for_regen: "TEST_COVERAGE_VALIDATION"  # Must have completed at least Phase 8

  # Clarification loop settings
  clarification:
    max_iterations: 2
    present_high_risk: true
    decomposition_offer: true

  # Validation settings
  validation:
    self_critique_min_pass: 4  # Out of 5 questions
    tdd_integration_min: 80    # Percentage of tasks with test refs
    format_compliance: true

  # Tech-lead agent configuration
  tech_lead:
    agent: "agents/tech-lead.md"
    use_sequential_thinking: true  # When ST MCP available
    st_templates: [T-TASK-DECOMPOSE, T-TASK-SEQUENCE, T-TASK-VALIDATE, T-TASK-FINALIZE]

  # Task format requirements
  format:
    checklist_prefix: "- [ ]"
    task_id_pattern: "T###"
    parallel_marker: "[P]"
    story_marker: "[US#]"
    require_file_path: true

  # Traceability output
  traceability:
    enabled: true
    output: "{FEATURE_DIR}/analysis/task-test-traceability.md"

  # Test execution order (V-Model phases)
  execution_order:
    - phase: pre_implementation
      tests: [unit]
      pattern: tdd_red
      description: "Write failing unit tests before code"

    - phase: during_implementation
      tests: [unit]
      pattern: tdd_green_refactor
      description: "Implement to pass tests, then refactor"

    - phase: post_implementation
      tests: [integration]
      pattern: verify_boundaries
      description: "Test component interactions"

    - phase: pre_merge
      tests: [e2e]
      pattern: critical_paths
      description: "Validate complete user flows"

    - phase: pre_release
      tests: [uat, exploratory]
      pattern: stakeholder_validation
      description: "Business acceptance and edge case discovery"

# =============================================================================
# ASSET CONSOLIDATION (Phase 8b)
# =============================================================================
# Configuration for asset discovery and manifest generation in Phase 8b

asset_consolidation:
  # No 'enabled' flag — Phase 8b always runs but auto-skips when zero assets detected.
  # To disable entirely, remove "8b" from orchestrator-loop.md dispatch list.
  skip_if_no_assets: true

  # Keyword lists for detecting asset references in planning artifacts
  detection:
    image_keywords: [image, photo, banner, logo, avatar, thumbnail, illustration, background, hero, screenshot, diagram]
    icon_keywords: [icon, glyph, symbol, indicator, badge, favicon]
    string_keywords: [label, message, text, copy, heading, title, description, placeholder, tooltip, error message, success message, notification]
    audio_keywords: [sound, audio, notification sound, alert, ringtone, music, beep]
    video_keywords: [video, animation, tutorial, demo, onboarding, walkthrough]
    font_keywords: [font, typeface, typography, custom font, icon font]
    config_keywords: [config, environment, env, API key, secret, feature flag, .env]
    fixture_keywords: [seed data, fixture, demo data, test data, sample, mock data]
    token_keywords: [design token, color palette, spacing, theme, dark mode, light mode]
    security_keywords: [certificate, HTTPS, SSL, TLS, OAuth, client ID, client secret]

  # Self-critique verification (Step 8b.3)
  self_critique:
    min_pass: 2  # out of 3 verification questions
    modes: [complete, advanced, standard]

  # Manifest output
  manifest:
    template: "$CLAUDE_PLUGIN_ROOT/templates/asset-manifest-template.md"
    output: "{FEATURE_DIR}/asset-manifest.md"

# =============================================================================
# OUTPUT ARTIFACTS
# =============================================================================

artifacts:
  required:
    - "{FEATURE_DIR}/plan.md"
    - "{FEATURE_DIR}/design.md"
    - "{FEATURE_DIR}/tasks.md"  # Generated in Phase 9

  optional:
    - "{FEATURE_DIR}/research.md"
    - "{FEATURE_DIR}/data-model.md"
    - "{FEATURE_DIR}/contract.md"
    - "{FEATURE_DIR}/analysis/thinkdeep-insights.md"
    - "{FEATURE_DIR}/analysis/consensus-validation.md"
    - "{FEATURE_DIR}/test-plan.md"
    - "{FEATURE_DIR}/analysis/test-coverage-validation.md"
    - "{FEATURE_DIR}/analysis/task-test-traceability.md"  # Task-to-test mapping
    - "{FEATURE_DIR}/asset-manifest.md"                  # Asset manifest from Phase 8b

# =============================================================================
# BLESSED CONFIGURATION PROFILES
# =============================================================================
# Tested flag combinations for each mode. Use these for CI validation.
# Each profile represents a validated configuration that has been tested end-to-end.

blessed_profiles:
  rapid_default:
    description: "Minimal analysis for prototypes and quick iterations"
    mode: rapid
    flags:
      s1_self_critique: true
      s2_cot_prefix: true
      a3_adaptive_depth: false
      a5_post_planning_menu: true
      # Multi-agent collaboration flags (not applicable to rapid mode)
      s7_mpa_deliberation: false
      s8_convergence_detection: false
      s10_team_presets: false
      s12_specify_gate: false
      s13_confidence_gated_review: false
      a6_context_protocol: false
    expected_cost: "$0.05-0.12"
    use_case: "Small features, quick prototypes, low-risk changes"

  standard_default:
    description: "Typical feature development with MPA"
    mode: standard
    flags:
      s1_self_critique: true
      s2_cot_prefix: true
      a3_adaptive_depth: true
      a5_post_planning_menu: true
      a1_flow_analysis: true
      a2_learnings_researcher: true
      # ST enhancements available in standard mode (if MCP available)
      st_tao_loops: true
      st_checkpoint: true
      st_task_decomposition: true
      # Multi-agent collaboration flags
      s7_mpa_deliberation: false     # Not applicable in standard mode
      s8_convergence_detection: false # Not applicable in standard mode
      s10_team_presets: false
      s12_specify_gate: false
      s13_confidence_gated_review: false  # Not applicable in standard mode
      a6_context_protocol: false
    expected_cost: "$0.20-0.40"  # Updated to reflect ST enhancements when MCP available
    use_case: "Normal features, moderate complexity, established patterns"

  advanced_default:
    description: "Important features requiring CLI deep analysis"
    mode: advanced
    flags:
      # All universal flags: true
      s1_self_critique: true
      s2_cot_prefix: true
      a3_adaptive_depth: true
      a5_post_planning_menu: true
      a1_flow_analysis: true
      a2_learnings_researcher: true
      # All advanced flags: true
      s3_judge_gates: true
      s4_adaptive_strategy: true
      a4_expert_review: true
      # CLI dispatch integration
      cli_context_isolation: true
      cli_custom_roles: true
      # Multi-agent collaboration flags (disabled by default)
      s7_mpa_deliberation: false
      s8_convergence_detection: false
      s10_team_presets: false
      s12_specify_gate: false
      s13_confidence_gated_review: false
      a6_context_protocol: false
    expected_cost: "$0.55-0.90"
    use_case: "Important features, risky changes, cross-cutting concerns"

  complete_default:
    description: "Critical features requiring full analysis"
    mode: complete
    flags:
      # All universal flags: true
      s1_self_critique: true
      s2_cot_prefix: true
      a3_adaptive_depth: true
      a5_post_planning_menu: true
      a1_flow_analysis: true
      a2_learnings_researcher: true
      # All advanced flags: true
      s3_judge_gates: true
      s4_adaptive_strategy: true
      a4_expert_review: true
      # All complete-only flags: true
      s5_tot_architecture: true
      s6_multi_judge_debate: true
      # Sequential Thinking enhancements (complete mode)
      st_fork_join_architecture: true
      st_revision_reconciliation: true
      st_redteam_analysis: true
      st_tao_loops: true
      st_dynamic_extension: true
      st_agent_invocation: true
      st_checkpoint: true
      st_task_decomposition: true
      # CLI dispatch integration
      cli_context_isolation: true
      cli_custom_roles: true
      # Multi-agent collaboration flags (disabled by default)
      s7_mpa_deliberation: false
      s8_convergence_detection: false
      s10_team_presets: false
      s12_specify_gate: false
      s13_confidence_gated_review: false
      a6_context_protocol: false
    expected_cost: "$1.10-2.00"  # Updated to reflect ST + CLI enhancements
    use_case: "Critical features, security-sensitive, high business impact"

  advanced_with_st:
    description: "Advanced mode with ST enhancements"
    mode: advanced
    flags:
      # All universal flags: true
      s1_self_critique: true
      s2_cot_prefix: true
      a3_adaptive_depth: true
      a5_post_planning_menu: true
      a1_flow_analysis: true
      a2_learnings_researcher: true
      # All advanced flags: true
      s3_judge_gates: true
      s4_adaptive_strategy: true
      a4_expert_review: true
      # ST enhancements available in advanced mode
      st_revision_reconciliation: true
      st_redteam_analysis: true
      st_tao_loops: true
      st_agent_invocation: true
      st_checkpoint: true
      st_task_decomposition: true
      # CLI dispatch integration
      cli_context_isolation: true
      cli_custom_roles: true
      # Complete-only flags: false
      st_fork_join_architecture: false
      st_dynamic_extension: false
      # Multi-agent collaboration flags (disabled by default)
      s7_mpa_deliberation: false
      s8_convergence_detection: false
      s10_team_presets: false
      s12_specify_gate: false
      s13_confidence_gated_review: false
      a6_context_protocol: false
    expected_cost: "$0.70-1.10"  # Updated to reflect ST + CLI enhancements
    use_case: "Important features requiring ST-enhanced analysis"

  # Profile with all multi-agent collaboration flags enabled (for CI testing)
  complete_with_collaboration:
    description: "Complete mode with all collaboration improvements enabled"
    mode: complete
    flags:
      # All universal flags: true
      s1_self_critique: true
      s2_cot_prefix: true
      a3_adaptive_depth: true
      a5_post_planning_menu: true
      a1_flow_analysis: true
      a2_learnings_researcher: true
      # All advanced flags: true
      s3_judge_gates: true
      s4_adaptive_strategy: true
      a4_expert_review: true
      # All complete-only flags: true
      s5_tot_architecture: true
      s6_multi_judge_debate: true
      # Sequential Thinking enhancements
      st_fork_join_architecture: true
      st_revision_reconciliation: true
      st_redteam_analysis: true
      st_tao_loops: true
      st_dynamic_extension: true
      st_agent_invocation: true
      st_checkpoint: true
      st_task_decomposition: true
      # CLI dispatch integration
      cli_context_isolation: true
      cli_custom_roles: true
      # Multi-agent collaboration flags: ALL ENABLED
      s7_mpa_deliberation: true
      s8_convergence_detection: true
      s10_team_presets: true
      s12_specify_gate: true
      s13_confidence_gated_review: true
      a6_context_protocol: true
    expected_cost: "$1.30-2.50"  # Higher due to deliberation re-dispatch + iteration rounds
    use_case: "Testing all collaboration improvements end-to-end"

  # Validation helper for CI
  validation:
    check_requires_dependencies: true
    check_mode_availability: true
    check_mcp_requirements: true

# =============================================================================
# RESEARCH MCP SERVERS
# =============================================================================
# Configuration for Context7, Ref, and Tavily research MCP servers
# See skills/plan/references/research-mcp-patterns.md for usage guidance

research_mcp:
  # Global budget and retry controls
  budget:
    total_calls_per_session: 25      # Max total research MCP calls per planning session
    total_calls_per_phase: 10        # Max calls per individual phase
    warn_at_percentage: 80           # Warn user when 80% of budget consumed

  retry:
    max_retries_per_call: 2          # Retry failed calls up to 2 times
    retry_delay_ms: 1000             # Wait 1 second between retries
    circuit_breaker_threshold: 3     # After 3 consecutive failures, skip server for session
    circuit_breaker_action: "graceful_skip"  # Options: graceful_skip, ask_user, abort

  # Context7 - Library documentation with code snippets
  context7:
    description: "Official library documentation with code examples"
    best_for: "Mainstream library API reference (React, Next.js, Express)"
    token_profile: "~3.3k avg (5k max)"

    # Efficiency controls
    max_calls_per_topic: 3  # Work with best result after 3 calls
    use_direct_ids: true     # Skip resolve-library-id when possible

    # Common library IDs to skip resolve-library-id
    common_library_ids:
      # Frontend Frameworks
      react: "/facebook/react"
      nextjs: "/vercel/next.js"
      vue: "/vuejs/core"
      angular: "/angular/angular"
      svelte: "/sveltejs/svelte"
      # Backend Frameworks
      express: "/expressjs/express"
      nestjs: "/nestjs/nest"
      fastify: "/fastify/fastify"
      # Databases & ORMs
      prisma: "/prisma/prisma"
      drizzle: "/drizzle-team/drizzle-orm"
      mongoose: "/Automattic/mongoose"
      typeorm: "/typeorm/typeorm"
      # Testing
      jest: "/jestjs/jest"
      vitest: "/vitest-dev/vitest"
      playwright: "/microsoft/playwright"
      cypress: "/cypress-io/cypress"
      # Auth
      nextauth: "/nextauthjs/next-auth"
      clerk: "/clerk/javascript"
      # State Management
      zustand: "/pmndrs/zustand"
      redux: "/reduxjs/redux"
      tanstack-query: "/TanStack/query"
      # Styling
      tailwind: "/tailwindlabs/tailwindcss"
      # TypeScript
      typescript: "/microsoft/typescript"

    # Query format guidance
    query_format:
      length: "5-15 words"
      style: "Specific, version-aware"
      example_good: "React 18 useEffect cleanup function patterns"
      example_bad: "react hooks"

  # Ref - Documentation with prose and private repos
  ref:
    description: "Docs with prose explanations, private repos, PDFs"
    best_for: "Detailed explanations, niche libraries, compliance docs"
    token_profile: "500-5k adaptive"

    # Efficiency controls
    search_before_read: true   # Always search first, then read selectively
    leverage_session_dedup: true  # Refine queries progressively

    # Query format guidance
    query_format:
      length: "10-20 words"
      style: "Full sentences, descriptive"
      example_good: "How to implement JWT authentication with NextAuth.js in Next.js 15"
      example_bad: "auth"

  # Tavily - Web search and current events
  tavily:
    description: "Web search for news, current events, security CVEs"
    best_for: "Recent announcements, breaking changes, vulnerability checks"
    cost_model: "1-2 credits/search, 4-250 for research"

    # Cost controls (CRITICAL)
    default_search_depth: "basic"  # Prevents 2x credit usage
    min_relevance_score: 0.5       # Filter out low-quality results
    default_max_results: 10

    # Query format guidance
    query_format:
      length: "5-10 words"
      style: "Search keywords, not conversational"
      max_chars: 400
      example_good: "Next.js 15 release notes changes 2026"
      example_bad: "Can you tell me about Next.js changes?"

    # ANTI-PATTERN WARNING
    never_use_for:
      - "Library API documentation (use Context7/Ref instead)"
      - "Framework tutorials (use Context7/Ref instead)"
      - "Official documentation lookup (use Context7/Ref instead)"

  # Server selection decision matrix
  selection_matrix:
    library_api_mainstream: "context7"
    library_api_niche: "ref"
    prose_explanations: "ref"
    private_repos: "ref"
    current_events: "tavily"
    news_announcements: "tavily"
    security_cve: "tavily"
    specific_url: "ref"

  # Multi-server workflow pattern
  multi_server_workflow:
    step_1:
      name: "documentation"
      server: "context7 OR ref"
      purpose: "Get official API reference"
    step_2:
      name: "recent_updates"
      server: "tavily"
      purpose: "Check for recent changes, breaking updates"
      condition: "risk_level >= medium OR technology_is_new"
      params:
        time_range: "month"
        topic: "news"
    step_3:
      name: "deep_dive"
      server: "ref"
      purpose: "Read full content of important URLs"
      condition: "step_2 found critical updates"
    step_4:
      name: "security_check"
      server: "tavily"
      purpose: "Check for known vulnerabilities"
      condition: "technology handles auth/payments/PII"

  # Graceful degradation
  degradation:
    context7_unavailable: "ref"
    ref_unavailable: "tavily with include_domains filter"
    all_unavailable: "proceed with internal knowledge, mark DEGRADED"

# =============================================================================
# CLI INTEGRATION
# =============================================================================
# Configuration for CLI dispatch (Bash process-group dispatch) with custom roles
# CLI dispatch infrastructure. See skills/plan/references/cli-dispatch-pattern.md
# Replaces both PAL clink MCP dispatch and PAL ThinkDeep/Consensus MCP tools.

cli_integration:
  # Dispatch script configuration
  dispatch:
    script_path: "$CLAUDE_PLUGIN_ROOT/scripts/dispatch-cli-agent.sh"

  # Instrumentation
  instrumentation:
    enabled: true
    capture_cli_version: true
    sidecar_retention: "session"

  # Auto-setup configuration
  auto_setup:
    source_dir: "$CLAUDE_PLUGIN_ROOT/templates/cli-roles/"
    target_dir: "PROJECT_ROOT/conf/cli_clients/"
    version_marker: "cli_role_version: 1.1.0"

  # Available CLIs and their capabilities
  clis:
    gemini:
      context_size: "1M tokens"
      capabilities: [web_search, sequential_thinking, broad_exploration]
      auto_approval_flag: "--yolo"
      best_for: "Broad codebase analysis, tech stack validation, pattern discovery"

    codex:
      context_size: "128K tokens"
      capabilities: [code_analysis, import_tracing, vulnerability_detection]
      auto_approval_flag: "--dangerously-bypass-approvals-and-sandbox"
      best_for: "Import chains, coupling analysis, code-level security, file path verification"

    opencode:
      context_size: "200K tokens"
      capabilities: [ux_analysis, accessibility_audit, user_flow_tracing, product_alignment]
      auto_approval_flag: ""  # Non-interactive mode auto-rejects permissions
      best_for: "User experience assessment, accessibility analysis, product alignment, user flow validation"

  # Multi-CLI MPA pattern
  multi_cli:
    enabled: true
    synthesis_strategy: "unanimous_majority_divergent_unique"
    # Unanimous (3 agree)  -> VERY HIGH confidence
    # Majority (2 agree)   -> HIGH confidence
    # All disagree         -> FLAG for user decision
    # Unique (1 only)      -> VERIFY against existing findings

  # Self-critique configuration
  self_critique:
    method: "st_cove_subagent"
    description: "Chain-of-Verification via Task(general-purpose) subagent"
    verification_questions:
      min: 3
      max: 5
    rationale: "Runs in separate context to avoid coordinator pollution"

  # Custom roles (6 roles x 2 CLIs = 12 prompt files)
  roles:
    deepthinker:
      gemini_focus: "Broad architecture exploration, tech stack, pattern conflicts"
      codex_focus: "Import chain analysis, coupling assessment, complexity hotspots"
      opencode_focus: "User flow impact analysis, accessibility implications, UX patterns, design system alignment"
      phases: [5]
      modes: [complete, advanced]

    consensus:
      gemini_focus: "Strategic plan/coverage assessment, broad codebase exploration"
      codex_focus: "Code-level feasibility verification, dependency checking, file:line evidence"
      opencode_focus: "Product alignment scoring, user story coverage, UX quality, feature completeness"
      phases: [6, 8]
      modes: [complete, advanced]

    planreviewer:
      gemini_focus: "Strategic risks, scope assessment, Red Team/Blue Team"
      codex_focus: "Technical feasibility, code structure support, dependency compatibility"
      opencode_focus: "Product risk assessment, user journey gaps, feature completeness from user perspective"
      phases: [6]
      modes: [complete, advanced]

    teststrategist:
      gemini_focus: "Test infra discovery, framework patterns, coverage gaps, ThinkDeep reconciliation"
      codex_focus: "Test code patterns, assertion quality, mock patterns, test isolation"
      opencode_focus: "UAT quality assessment, user acceptance scenarios, accessibility testing, exploratory testing"
      phases: [7]
      modes: [complete]

    securityauditor:
      gemini_focus: "Supply chain security, architectural attack surface, compliance"
      codex_focus: "OWASP code-level vulnerabilities, injection points, hardcoded secrets"
      opencode_focus: "User data privacy, consent flows, PII handling, security UX (error messages, auth flows)"
      phases: [6b]
      modes: [complete, advanced]

    taskauditor:
      gemini_focus: "Requirements mapping, missing infrastructure, scope coverage"
      codex_focus: "File path verification, dependency ordering, code structure alignment"
      opencode_focus: "User story coverage, definition of done alignment, UX task completeness, missing user-facing tasks"
      phases: [9]
      modes: [complete, advanced]

  # Retry and circuit breaker
  retry:
    max_retries: 1
    circuit_breaker_threshold: 2  # After 2 consecutive failures, skip CLI dispatch for session

  # Timeout configuration
  timeout:
    default_seconds: 120
    per_role:
      deepthinker: 180   # Broad exploration needs more time
      consensus: 120     # Dimensional scoring with stance
      planreviewer: 120
      teststrategist: 150
      securityauditor: 150
      taskauditor: 120
    per_cli:
      gemini: 120        # Fast with large context
      codex: 90          # Fastest for code-level analysis
      opencode: 150      # UX analysis may need more time

  # Latency estimates (per-role, includes all CLIs + synthesis + self-critique)
  latency:
    deepthinker: "75-120s"
    planreviewer: "60-90s"
    teststrategist: "75-120s"
    securityauditor: "75-120s"
    taskauditor: "60-90s"
    total_cumulative: "~6-9 min for all roles"

  # Fallback behavior
  fallback:
    if_cli_unavailable: "skip_cli_steps"
    if_one_cli_missing: "reduced_cli_mode"
    if_two_cli_missing: "single_cli_mode"
    if_all_missing: "skip_cli_steps"
    log_fallback: true

# =============================================================================
# DEV-SKILLS INTEGRATION
# =============================================================================
# Enrich subagent prompts with domain expertise from the co-installed dev-skills plugin.
# Uses subagent-delegated skill loading to avoid coordinator context pollution.
# See skills/plan/references/skill-loader-pattern.md for the canonical dispatch pattern.

dev_skills_integration:
  enabled: true
  description: "Enrich subagent prompts with domain expertise from dev-skills plugin"
  rollback: "Set false to disable all skill injection"
  modes: [complete, advanced, standard]  # NOT rapid

  # Context budget per skill context file (approximate tokens)
  context_budget:
    max_per_skill_extraction: 1200  # Max tokens extracted per individual skill
    max_per_phase_context_file: 3000  # Max total in skill-context.md per phase
    max_injected_per_agent: 1500  # Max skill context injected into a single agent prompt

  # Detection keywords for tech-stack identification (case-insensitive scan of spec.md)
  detection:
    frontend: [react, next, vue, angular, svelte, tailwind, css, html, jsx, tsx]
    mobile: [android, ios, kotlin, swift, compose, react-native, flutter, kmp]
    backend_api: [rest, graphql, trpc, api, endpoint, route, controller, middleware]
    database: [postgres, mysql, sqlite, mongo, prisma, drizzle, schema, migration, orm]
    figma: [figma, design system, design tokens, component library]
    build: [gradle, webpack, vite, turbopack, esbuild]

  # Codebase file markers for detection (scan project root for these files)
  codebase_markers:
    "package.json": [frontend, backend_api]
    "build.gradle.kts": [mobile, build]
    "settings.gradle.kts": [mobile, build]
    "Podfile": [mobile]
    "pubspec.yaml": [mobile]
    "tsconfig.json": [frontend]
    "tailwind.config.*": [frontend]
    ".xcodeproj": [mobile]

  # Domain-to-skill mapping (used by skill loader subagents)
  domain_skills:
    architecture:
      always: true
      skills:
        - skill: api-patterns
          extract: "API style decision tree, auth patterns, OWASP Top 10"
        - skill: c4-architecture
          extract: "Element syntax, diagram levels, Mermaid C4 examples"
        - skill: clean-code
          extract: "Core principles, anti-patterns table, function rules"
        - skill: mermaid-diagrams
          extract: "C4 diagram syntax, quick start examples"
    database:
      always: false
      skills:
        - skill: database-design
          extract: "Selection decision tree, ORM comparison"
        - skill: database-schema-designer
          extract: "Normalization principles, anti-patterns"
    frontend:
      always: false
      skills:
        - skill: frontend-design
          extract: "Decision framework, aesthetic directions"
        - skill: web-design-guidelines
          extract: "Code quality rules, performance checklist"
        - skill: accessibility-auditor
          extract: "Quick audit checklist, POUR principles"
    mobile:
      always: false
      skills:
        - skill: mobile-design  # registered, not yet wired into phase loaders
          extract: "Touch-first principles, AI anti-patterns"
        - skill: android-expert  # registered, not yet wired into phase loaders
          extract: "Navigation patterns, Material3 setup"
        - skill: kotlin-expert
          extract: "Flow patterns, sealed hierarchies"
        - skill: compose-expert
          extract: "Shared composable anatomy, recomposition"
        - skill: gradle-expert
          extract: "Build architecture layers, version catalog"
        - skill: kotlin-coroutines  # registered, not yet wired into phase loaders
          extract: "Structured concurrency, Flow operators"
    figma:
      always: false
      skills:
        - skill: figma-implement-design
          extract: "Quick workflow, URL parsing"
        - skill: figma-code-connect-components  # registered, not yet wired into phase loaders
          extract: "Mapping workflow"
        - skill: figma-create-design-system-rules  # registered, not yet wired into phase loaders
          extract: "Rule generation workflow"
        - skill: figma-design-toolkit
          extract: "Token extraction, design auditing"
    qa:
      always: true
      skills:
        - skill: qa-test-planner
          extract: "Regression suite types, priority defs, severity defs"

# =============================================================================
# DEEP REASONING ESCALATION
# =============================================================================
# Integration with external deep reasoning models (GPT-5 Pro, Google Deep Think)
# for tasks where Claude's gate-retry loop fails to produce passing results.
# User manually submits prompt to the model's web interface and returns the result.
# See skills/plan/references/deep-reasoning-dispatch-pattern.md

deep_reasoning_escalation:
  # --- Feature Flags (all disabled by default) ---
  circular_failure_recovery:
    enabled: false
    description: "Offer deep reasoning escalation after 2 gate retries fail"
    rollback: "Set false to use existing retry/skip/abort flow"
    modes: [complete, advanced]
    requires_mcp: false  # Manual user submission, no MCP needed
    cost_impact: "0 API cost; 3-15 min user wait time per escalation"
    applies_to: "All gates (Phase 2, 4, 6, 7, 8)"

  architecture_wall_breaker:
    enabled: false
    description: "Architecture-specific escalation when Phase 6 RED loops to Phase 4"
    rollback: "Set false to use generic circular failure recovery"
    modes: [complete, advanced]
    requires_mcp: false
    cost_impact: "0 API cost; 5-15 min user wait time"
    requires: [circular_failure_recovery]
    applies_to: "Phase 6 RED → Phase 4 loop"

  security_deep_dive:
    enabled: false
    description: "CVE-level deep reasoning audit when 2+ CRITICAL security findings"
    rollback: "Set false to use standard security review only"
    modes: [complete, advanced]
    requires_mcp: false
    cost_impact: "0 API cost; 5-15 min user wait time"
    trigger:
      min_critical_findings: 2
      severity_levels: [CRITICAL]
    applies_to: "Phase 6b security findings"

  abstract_algorithm_detection:
    enabled: false
    description: "Detect algorithm/math keywords in spec for potential later escalation"
    rollback: "Set false to skip detection (no escalation offered in later phases)"
    modes: [complete, advanced]
    requires_mcp: false
    cost_impact: "0 API cost; detection only (later escalation adds 3-15 min user wait)"
    detection_phase: 1

  # --- Detection Keywords (case-insensitive scan of spec.md) ---
  algorithm_keywords:
    high_confidence:
      - "proof"
      - "theorem"
      - "formal verification"
      - "mathematical optimization"
      - "NP-hard"
      - "NP-complete"
      - "constraint solver"
      - "SAT solver"
      - "linear programming"
      - "dynamic programming"
      - "cryptographic"
      - "zero-knowledge"
    moderate_confidence:
      - "algorithm"
      - "heuristic"
      - "optimization"
      - "state machine"
      - "parser"
      - "compiler"
      - "sorting"
      - "pathfinding"

  # --- Context Length Limits for CTCO Prompts (tokens) ---
  context_limits:
    architecture_wall: { min: 16000, max: 32000 }
    circular_failure: { min: 10000, max: 20000 }
    security_deep_dive: { min: 32000, max: 64000 }
    algorithm_escalation: { min: 4000, max: 16000 }

  # --- Escalation Attempt Limits ---
  limits:
    max_escalations_per_session: 3
    max_escalations_per_phase: 1
    stale_timeout_minutes: 30  # Pending escalation older than this is considered stale on resume

  # --- Supported Models (informational, for user guidance) ---
  supported_models:
    - name: "GPT-5 Pro / GPT-5.2 Pro"
      interface: "chat.openai.com (Pro subscription)"
      latency: "3-15 min"
    - name: "Google Deep Think"
      interface: "AI Studio / Gemini Advanced"
      latency: "2-10 min"

# =============================================================================
# RETROSPECTIVE (Phase 10)
# =============================================================================
retrospective:
  enabled: true
  transcript_analysis:
    enabled: true
    transcript_dir: null
    max_errors_extracted: 20
    max_file_paths_extracted: 50
    extract_token_budget: 3000
  auto_commit:
    enabled: true
    message_template: "docs({feature_name}): add planning retrospective"
    exclude_patterns:
      - ".planning-report-card.local.md"
      - "transcript-extract.json"
      - ".planning-state.local.md"
      - ".phase-summaries/"
  sections:
    timeline: true
    what_worked: true
    what_didnt_work: true
    phase_breakdown: true
    tool_analysis: true
    recommendations: true
    raw_metrics: true
